{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "task1_28905644.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3jZz7FM-hP5",
        "colab_type": "text"
      },
      "source": [
        "# FIT 5196: ASSIGNMENT 1 - TASK 1: Parsing Raw Text Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7Uh0yQ7-hP6",
        "colab_type": "text"
      },
      "source": [
        "## 1) Introduction\n",
        "This task aims at preprocessing and analyzing textual data containing important information such as Unit ID, Unit Name, Pre Requisites, Prohibitions, Synopsis, Requirement, Outputs and Chief Examiners for each unit. The code extracts aforementioned information from the text containing the information for 400 different units and presents the information in xml and json format in files labelled **28905644.json** and **28905644.xml**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v84xCwYT-hP6",
        "colab_type": "text"
      },
      "source": [
        "## 2) Approach/Methodology\n",
        "The following points list down the approach used in extracting the data for all the units in json and xml format:\n",
        "\n",
        "1) After reading the **2895644.txt** file, regular expression is used to separate data for each unit in the file and stored as string in a list conntaining data for all units.\n",
        "\n",
        "2) Independent regular expressions are than used to obtain Unit ID, Unit Name, Pre Requisites, Prohibitions, Synopsis, Requirement, Outputs and Chief Examiners for each unit and the information stored in separate list for each of the units.\n",
        "\n",
        "3) These lists are than used to create a dictionary with key value pairs of all information for each unit and than converted to json file using json library.\n",
        "\n",
        "4) Lastly,a string is used to map data as per xml format with tags appended and than written down in an xml file to produce the xml information of the units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-rloE93-hP7",
        "colab_type": "text"
      },
      "source": [
        "## 3) Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86iiTCVw-hP7",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 File reading and separating data for each unit\n",
        "The standard python functionality is used to read data and *finditer* from re library is used to segregate data for each unit.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZppGT7C-hP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "# read the whole file\n",
        "infile=open('28905644.txt','r').read()\n",
        "\n",
        "# parse each units data separately\n",
        "matches_unit_data = re.finditer(r'<div class=\\\"content-inner__main\\\">(\\n.*?)*<!-- \\/\\.content-inner__main --><\\/div>\\n', infile) # contains regular expression to segregate data for each unit from the file\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAHkKmm4-hP_",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Extracting each information from each of the units information and adding to it's respective list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww6Z4ULj-hP_",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2.1 Unit Code\n",
        "The regular expression is used to extract information from each unit data and than converted to string from, which is than appended to unit code list.\n",
        "\n",
        "#### 3.2.2 Unit Title\n",
        "The regular expression is used to extract information from each unit data and than converted to string from, which is than appended to unit title list.\n",
        "\n",
        "#### 3.2.3 Pre Requisites & Co Requisites\n",
        "2 separate regular expressions are used to extract raw informations for each of pre requisites and co requisites respectively. That information is than added to a common string containing **both** pre reqs and co reqs raw data for each unit. Unit codes are than extracted from this string using another regular expression in a list (list_unit_prereqs). If there are no unitcodes in the combined string a \"NA\" is appended else the list of all unit codes for a given unit is appended to master list.\n",
        "\n",
        "#### 3.2.4 Prohibitions\n",
        "Likewise, after obtaining the string containing prohibitions for a unit, regular expression is used to obtain a list of prohibted units and appended to the master list (containing data for all units).\n",
        "\n",
        "#### 3.2.5 Synopsis\n",
        "After identifying synopsis tag in each unit using a regular expression, a regular expression is used to identify the synopsis portion of the unit, that is than cleaned of all html tags, end of line charachters and + using sub function in re library. It is than appended to the master list containing synopsis string for each unit.\n",
        "\n",
        "#### 3.2.6 Requirements\n",
        "After identifying Requirements tag in each unit using a regular expression and obtaining string for the requirements, a regular expression is used to obtain and clean the string for requirements (that is than cleaned of all html tagsusing sub function in re library). It is than appended to the master list containing list of requirements for each unit.\n",
        "\n",
        "#### 3.2.7 Outcomes\n",
        "After identifying Outcomes tag in each unit using a regular expression and obtaining string for the outcomes, a regular expression is used to clean the string for outcomes (that is than cleaned of all html tagsusing sub function in re library) and obtain list of outcomes. It is than appended to the master list containing list of outcomes for each unit.\n",
        "\n",
        "#### 3.2.8 Chief Examiners\n",
        "After obtaining chief examiners tag, The names of examiners are extracted using a set of 2 regular expressions in a list that are than added to master list as per the scenarios explained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjPb_Wo1-hQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count=0\n",
        "unit_code=[]\n",
        "unit_title=[]\n",
        "unit_prereqs=[]\n",
        "unit_prohibitions=[]\n",
        "unit_synopsis=[]\n",
        "unit_requirements=[]\n",
        "unit_examiners=[]\n",
        "unit_outcomes=[]\n",
        "for each in matches_unit_data:\n",
        "    \n",
        "    ##*********Unit code extraction goes here*********\n",
        "    \n",
        "    matches_unit_code=re.findall(r'<span class=\"unitcode\">([A-Z]{3,4}[0-9]{4})<\\/span>',each.group())\n",
        "    string_unit_code=str(matches_unit_code[0])\n",
        "    unit_code.append(string_unit_code)\n",
        "\n",
        "    ##*********Unit title extraction goes here*********\n",
        "    matches_unit_title=re.findall(r'<\\/span> - (.*?)<span class=\"hbk-archive-only\">',each.group())\n",
        "    string_unit_title=str(matches_unit_title[0])\n",
        "    unit_title.append(string_unit_title)\n",
        "\n",
        "    \n",
        "    ##*********Pre requisites & Co requisites extraction goes here*********\n",
        "    matches_unit_prereqs=re.finditer(r'<p class=\"hbk-preamble-heading\">Prerequisites<\\/p>(\\n.*?)*<\\/p>',each.group())\n",
        "    matches_unit_coreqs=re.finditer(r'<p class=\"hbk-preamble-heading\">Co-requisites</p>(\\n.*?)*<\\/p>',each.group())\n",
        "\n",
        "    list_unit_prereqs=[]\n",
        "    prereqs=\"\"\n",
        "    for each5 in matches_unit_prereqs:\n",
        "        prereqs=each5.group()\n",
        "    tempabcd=\"\"\n",
        "    for each6 in matches_unit_coreqs:\n",
        "        tempabcd=each6.group()\n",
        "\n",
        "    prereqs+=tempabcd\n",
        "    if prereqs!=\"\":\n",
        "        list_unit_prereqs=re.findall(r'([A-Z]{3,4}[0-9]{4})[< ,]',prereqs)\n",
        "        list_unit_prereqs=list(dict.fromkeys(list_unit_prereqs)) #remove duplicates\n",
        "\n",
        "        if len(list_unit_prereqs)==0:\n",
        "            list_unit_prereqs.append('NA')\n",
        "\n",
        "        unit_prereqs.append(list_unit_prereqs)\n",
        "    else:\n",
        "        list_unit_prereqs.append('NA')\n",
        "        unit_prereqs.append(list_unit_prereqs)\n",
        "\n",
        "    ##*********Prohibitions extraction goes here*********\n",
        "    matches_unit_prohib=re.finditer(r'<p class=\"hbk-preamble-heading\">Prohibitions<\\/p>(\\n.*?)*<\\/p>',each.group())\n",
        "\n",
        "    list_unit_prohib=[]\n",
        "\n",
        "    prohibitions=\"\"\n",
        "    \n",
        "    for each7 in matches_unit_prohib:\n",
        "        prohibitions=each7.group()\n",
        "    \n",
        "    if prohibitions!=\"\":\n",
        "        list_unit_prohib=re.findall(r'([A-Z]{3,4}[0-9]{4})[.< ,]',prohibitions)\n",
        "        list_unit_prohib=list(dict.fromkeys(list_unit_prohib))\n",
        "        if len(list_unit_prohib)==0:\n",
        "            list_unit_prohib.append('NA')\n",
        "\n",
        "\n",
        "        unit_prohibitions.append(list_unit_prohib)\n",
        "    else:\n",
        "        list_unit_prohib.append('NA')\n",
        "        unit_prohibitions.append(list_unit_prohib)\n",
        "    \n",
        "\n",
        "    ##*********Synopsis extraction goes here*********\n",
        "    matches_unit_synopsis=re.finditer(r'<h2 class=\"hbk-heading\">(Synopsis<\\/h2>(\\n.*?)*)<\\/div>',each.group())\n",
        "\n",
        "    \n",
        "    temp=\"\"\n",
        "    for each1 in matches_unit_synopsis:\n",
        "        temp=each1.group()\n",
        "    if temp!=\"\":\n",
        "        list_unit_synopsis=re.findall(r'<p>(.*?)<\\/p>',temp)\n",
        "        if len(list_unit_synopsis)==0:\n",
        "            string_unit_synopsis=\"NA\"\n",
        "        else:\n",
        "            string_unit_synopsis=list_unit_synopsis[0]\n",
        "            \n",
        "        string_unit_synopsis=re.sub(r'<.*?>',\"\",string_unit_synopsis)# https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
        "        \n",
        "        string_unit_synopsis=re.sub(r'\\n',\" \",string_unit_synopsis)\n",
        "        #string_unit_synopsis=string_unit_synopsis[10:]\n",
        "        string_unit_synopsis=re.sub(' +', ' ',string_unit_synopsis)\n",
        "        string_unit_synopsis=re.sub('&amp', '',string_unit_synopsis)\n",
        "        #print(string_unit_synopsis)\n",
        "        #print(\"\\n\")\n",
        "\n",
        "        unit_synopsis.append(string_unit_synopsis)\n",
        "    else:\n",
        "        unit_synopsis.append(\"NA\")\n",
        "    \n",
        "\n",
        "\n",
        "    ##*********requirements extraction goes here*********\n",
        "    matches_unit_requirements=re.finditer(r'<h2 class=\"hbk-heading\">Assessment<\\/h2>(\\n.*?)*<\\/div>',each.group())\n",
        "\n",
        "    list_unit_requirements=[]\n",
        "    temp=\"\"\n",
        "    for each2 in matches_unit_requirements:\n",
        "        temp=each2.group()\n",
        "\n",
        "    if temp!=\"\":\n",
        "        list_unit_requirements=re.findall(r'<p>.*?<\\/p>',temp)\n",
        "        for ind,val in enumerate(list_unit_requirements):\n",
        "            val=re.sub('&amp', '',val)\n",
        "            temp1=re.sub(r'<.*?>',\"\",val)\n",
        "            list_unit_requirements[ind]=temp1\n",
        "\n",
        "        if len(list_unit_requirements)==0:\n",
        "            list_unit_requirements.append('NA')\n",
        "        unit_requirements.append(list_unit_requirements)\n",
        "    else:\n",
        "        list_unit_requirements.append('NA')\n",
        "        unit_requirements.append(list_unit_requirements)\n",
        "\n",
        "    ##*********Outcomes extraction goes here*********\n",
        "    matches_unit_outcomes=re.finditer(r'<h2 class=\"hbk-heading\">Outcomes<\\/h2>(\\n.*?)*<\\/div>',each.group())\n",
        "    list_unit_outcomes=[]\n",
        "    tempy=\"\"\n",
        "    for each3 in matches_unit_outcomes:\n",
        "        tempy=each3.group()\n",
        "\n",
        "    if tempy!=\"\":\n",
        "        list_unit_outcomes=re.findall(r'<li>(.*?[.;]?(\\n?.*?)*)<\\/li>?',tempy)\n",
        "        list_unit_outcomes = [i[0] for i in list_unit_outcomes]\n",
        "        for ind,val in enumerate(list_unit_outcomes):\n",
        "            #if val==\"&amp\":\n",
        "            val=re.sub('&amp', '',val)\n",
        "            tempz=re.sub(r'<.*?>',\"\",val)\n",
        "            list_unit_outcomes[ind]=tempz\n",
        "\n",
        "        if len(list_unit_outcomes)==0:\n",
        "            list_unit_outcomes.append('NA')\n",
        "        unit_outcomes.append(list_unit_outcomes)\n",
        "    else:\n",
        "        list_unit_outcomes.append('NA')\n",
        "        unit_outcomes.append(list_unit_outcomes)\n",
        "\n",
        "\n",
        "    ##*********Chief examiners extraction goes here*********\n",
        "    matches_chief_examiners=re.finditer(r'<p class=\"hbk-highlight-heading\">Chief examiner\\(s\\)<\\/p>((\\n.*?)*)<\\/p>',each.group())\n",
        "\n",
        "    list_chief_examiners=[]\n",
        "    tempx=\"\"\n",
        "    for each4 in matches_chief_examiners:\n",
        "        tempx=each4.group()\n",
        "\n",
        "    if tempx!=\"\": # tag of chief examiners present\n",
        "        find1=[]\n",
        "        find1=re.findall(r'((\\n.*?)*?<br\\/>)',tempx)\n",
        "        for eachx in find1:\n",
        "            find2=re.findall(r'<a href=.*>(.*?)<\\/a>',str(eachx))\n",
        "            list_chief_examiners.append(find2)\n",
        "\n",
        "        if len(list_chief_examiners[0])==0 and len(list_chief_examiners)==1: #No chief examiners info\n",
        "            unit_examiners.append(\"TBA\")    \n",
        "        elif len(list_chief_examiners[0])==1 and len(list_chief_examiners)==1: # 1 chief examiner\n",
        "            temp_str=list_chief_examiners[0][0]\n",
        "            temp_str=temp_str.replace('\\\\',\"\")\n",
        "            unit_examiners.append(temp_str)\n",
        "        else: #multiple chief examiners\n",
        "            temp_list=[]\n",
        "            for each in list_chief_examiners:\n",
        "                if len(each)!=0:\n",
        "                    each[0]=each[0].replace('\\\\',\"\")\n",
        "                    temp_list.append(each[0])\n",
        "            unit_examiners.append(temp_list)\n",
        "    else: # No tag for chief examiner\n",
        "        unit_examiners.append(\"TBA\")\n",
        "\n",
        "    \n",
        "    count+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3FyRqys-hQC",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Dictionary for json\n",
        "Dictionary is than created to add data from the master list in a dictionary of list of dictionaries format (as in the sample json output)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYpx6fdJ-hQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#*****Creating Dictionary for json**********\n",
        "\n",
        "dictionary_unit_list=[]\n",
        "\n",
        "for i in range(count):\n",
        "    dictionary_unit_inner={}\n",
        "\n",
        "    dictionary_unit_inner['@id']=unit_code[i]\n",
        "    dictionary_unit_inner['title']=unit_title[i]\n",
        "    dictionary_unit_inner['synopsis']=unit_synopsis[i]\n",
        "\n",
        "    dict_pre_requistics={}\n",
        "    if len(unit_prereqs[i])==1 and unit_prereqs[i][0]=='NA':\n",
        "        dictionary_unit_inner['pre_requistics']=unit_prereqs[i][0]\n",
        "\n",
        "    elif len(unit_prereqs[i])==1 and unit_prereqs[i][0]!='NA':\n",
        "        dict_pre_requistics['pre_requistic']=unit_prereqs[i][0]\n",
        "        dictionary_unit_inner['pre_requistics']=dict_pre_requistics\n",
        "\n",
        "    elif len(unit_prereqs[i])>1:\n",
        "        dict_pre_requistics['pre_requistic']=unit_prereqs[i]\n",
        "        dictionary_unit_inner['pre_requistics']=dict_pre_requistics\n",
        "\n",
        "\n",
        "    dict_prohibisions={}\n",
        "    if len(unit_prohibitions[i])==1 and unit_prohibitions[i][0]=='NA':\n",
        "        dictionary_unit_inner['prohibisions']=unit_prohibitions[i][0]\n",
        "\n",
        "    elif len(unit_prohibitions[i])==1 and unit_prohibitions[i][0]!='NA':\n",
        "        dict_prohibisions['prohibision']=unit_prohibitions[i][0]\n",
        "        dictionary_unit_inner['prohibisions']=dict_prohibisions\n",
        "\n",
        "    elif len(unit_prohibitions[i])>1:\n",
        "        dict_prohibisions['prohibision']=unit_prohibitions[i]\n",
        "        dictionary_unit_inner['prohibisions']=dict_prohibisions\n",
        "\n",
        "\n",
        "    dict_requirements={}\n",
        "    if len(unit_requirements[i])==1 and unit_requirements[i][0]=='NA':\n",
        "        dictionary_unit_inner['requirements']=unit_requirements[i][0]\n",
        "\n",
        "    elif len(unit_requirements[i])==1 and unit_requirements[i][0]!='NA':\n",
        "        dict_requirements['requirement']=unit_requirements[i][0]\n",
        "        dictionary_unit_inner['requirements']=dict_requirements\n",
        "\n",
        "    elif len(unit_requirements[i])>1:\n",
        "        dict_requirements['requirement']=unit_requirements[i]\n",
        "        dictionary_unit_inner['requirements']=dict_requirements\n",
        "\n",
        "\n",
        "    dict_outcomes={}\n",
        "    if len(unit_outcomes[i])==1 and  unit_outcomes[i][0]=='NA':\n",
        "        dictionary_unit_inner['outcomes']=unit_outcomes[i][0]\n",
        "    elif len(unit_outcomes[i])==1 and  unit_outcomes[i][0]!='NA':\n",
        "        dict_outcomes['outcome']=unit_outcomes[i][0]\n",
        "        dictionary_unit_inner['outcomes']=dict_outcomes\n",
        "    elif len(unit_outcomes[i])>1:\n",
        "        dict_outcomes['outcome']=unit_outcomes[i]\n",
        "        dictionary_unit_inner['outcomes']=dict_outcomes\n",
        "\n",
        "\n",
        "    dict_chief_examiners={}\n",
        "    \n",
        "    if unit_examiners[i]==\"TBA\":\n",
        "        dictionary_unit_inner['chief_examiners']=unit_examiners[i]\n",
        "    elif unit_examiners[i]!=\"TBA\" and type(unit_examiners[i]) is str:\n",
        "        dict_chief_examiners['chief_examiner']=unit_examiners[i]\n",
        "        dictionary_unit_inner['chief_examiners']=dict_chief_examiners\n",
        "    else:\n",
        "        dict_chief_examiners['chief_examiner']=unit_examiners[i]\n",
        "        dictionary_unit_inner['chief_examiners']=dict_chief_examiners\n",
        "\n",
        "                  \n",
        "    dictionary_unit_list.append(dictionary_unit_inner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yob8bik-hQG",
        "colab_type": "text"
      },
      "source": [
        "### 3.3.1 Writing to json file\n",
        "A dictionary for unit and dictionary for units is created and than json dump to write in the json file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CZkcPMW-hQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary_unit={}\n",
        "dictionary_unit['unit']=dictionary_unit_list\n",
        "\n",
        "dictionary_units={}\n",
        "dictionary_units['units']=dictionary_unit\n",
        "\n",
        "with open('28905644.json','w+') as xfile:\n",
        "    json.dump(dictionary_units,xfile,indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYdTkges-hQJ",
        "colab_type": "text"
      },
      "source": [
        "### 3.4 String for xml\n",
        "String is than created to add data from the master lists in a string with tags (as in the sample xml output)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQTVZHCd-hQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#****Creating xml here*****\n",
        "full_string=\"\"\n",
        "string_units=\"<units>\\n\"\n",
        "full_string+=string_units\n",
        "for j in range(count):\n",
        "    unit_string=\"\"\n",
        "    string_unit=\"\"\n",
        "    string_unit=\"<unit id=\"+\"'\"+unit_code[j]+\"'\"+\">\\n\"\n",
        "    unit_string+=string_unit\n",
        "    #print(string_unit)\n",
        "    string_title=\"\"\n",
        "    string_title=\"<title>\"+\" \"+unit_title[j]+\"</title>\\n\"\n",
        "    unit_string+=string_title\n",
        "    string_synopsis=\"\"\n",
        "    string_synopsis=\"<synopsis>\"+\" \"+unit_synopsis[j]+\"</synopsis>\\n\"\n",
        "    unit_string+=string_synopsis\n",
        "\n",
        "    if \"NA\" not in unit_prereqs[j]:\n",
        "        string_prerequisite1=\"<pre_requistics>\\n\"\n",
        "        unit_string+=string_prerequisite1\n",
        "        string_prerequisite2=\"\"\n",
        "        for one in unit_prereqs[j]:\n",
        "            temp=\"\"\n",
        "            temp=\"<pre_requistic>\"+one+\"</pre_requistic>\"\n",
        "            string_prerequisite2+=temp\n",
        "        string_prerequisite2+=\"</pre_requistics>\\n\"\n",
        "        unit_string+=string_prerequisite2\n",
        "    else:\n",
        "        string_prerequisite2=\"\"\n",
        "        string_prerequisite2=\"<pre_requistics>\"+\" \"+unit_prereqs[j][0]+\" \"+\"</pre_requistics>\\n\"\n",
        "        unit_string+=string_prerequisite2\n",
        "\n",
        "    if \"NA\" not in unit_prohibitions[j]:\n",
        "        string_prohib1=\"<prohibisions>\\n\"\n",
        "        unit_string+=string_prohib1\n",
        "        string_prohib2=\"\"\n",
        "        for one in unit_prohibitions[j]:\n",
        "            temp=\"\"\n",
        "            temp=\"<prohibision>\"+one+\"</prohibision>\"\n",
        "            string_prohib2+=temp\n",
        "        string_prohib2+=\"</prohibisions>\\n\"\n",
        "        unit_string+=string_prohib2\n",
        "    else:\n",
        "        string_prohib2=\"\"\n",
        "        string_prohib2=\"<prohibisions>\"+\" \"+unit_prohibitions[j][0]+\" \"+\"</prohibisions>\\n\"\n",
        "        unit_string+=string_prohib2\n",
        "\n",
        "    if \"NA\" not in unit_requirements[j]:\n",
        "        string_req1=\"<requirements>\\n\"\n",
        "        unit_string+=string_req1\n",
        "        string_req2=\"\"\n",
        "        for one in unit_requirements[j]:\n",
        "            temp=\"\"\n",
        "            temp=\"<requirement>\"+one+\"</requirement>\"\n",
        "            string_req2+=temp\n",
        "        string_req2+=\"</requirements>\\n\"\n",
        "        unit_string+=string_req2\n",
        "    else:\n",
        "        string_req2=\"\"\n",
        "        string_req2=\"<requirements>\"+\" \"+unit_requirements[j][0]+\" \"+\"</requirements>\\n\"\n",
        "        unit_string+=string_req2\n",
        "\n",
        "    if \"NA\" not in unit_outcomes[j]:\n",
        "        string_out1=\"<outcomes>\\n\"\n",
        "        unit_string+=string_out1\n",
        "        string_out2=\"\"\n",
        "        for one in unit_outcomes[j]:\n",
        "            temp=\"\"\n",
        "            temp=\"<outcome>\"+one+\"</outcome>\"\n",
        "            string_out2+=temp\n",
        "        string_out2+=\"</outcomes>\\n\"\n",
        "        unit_string+=string_out2\n",
        "    else:\n",
        "        string_out2=\"\"\n",
        "        string_out2=\"<outcomes>\"+\" \"+unit_outcomes[j][0]+\" \"+\"</outcomes>\\n\"\n",
        "        unit_string+=string_out2\n",
        "\n",
        "    if type(unit_examiners[j]) is list:\n",
        "        if \"TBA\" not in unit_examiners[j]:\n",
        "            string_exam1=\"<chief_examiners>\\n\"\n",
        "            unit_string+=string_exam1\n",
        "            string_exam2=\"\"\n",
        "            for one in unit_examiners[j]:\n",
        "                temp=\"\"\n",
        "                temp=\"<chief_examiner>\"+one+\"</chief_examiner>\"\n",
        "                string_exam2+=temp\n",
        "            string_exam2+=\"</chief_examiners>\\n\"\n",
        "            unit_string+=string_exam2\n",
        "        else:\n",
        "            string_exam2=\"\"\n",
        "            string_exam2=\"<chief_examiners>\"+\" \"+unit_examiners[j][0]+\" \"+\"</chief_examiners>\\n\"\n",
        "            unit_string+=string_exam2\n",
        "    elif type(unit_examiners[j]) is str:\n",
        "        if unit_examiners[j]==\"TBA\":\n",
        "            string_exam2=\"\"\n",
        "            string_exam2=\"<chief_examiners>\"+\" \"+unit_examiners[j]+\" \"+\"</chief_examiners>\\n\"\n",
        "            unit_string+=string_exam2\n",
        "        else:\n",
        "            string_exam1=\"<chief_examiners>\\n\"\n",
        "            unit_string+=string_exam1\n",
        "            string_exam2=\"\"\n",
        "            string_exam2=\"<chief_examiner>\"+unit_examiners[j]+\"</chief_examiner>\"\n",
        "            string_exam2+=\"</chief_examiners>\\n\"\n",
        "            unit_string+=string_exam2\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "    unit_string+=\"</unit>\\n\"\n",
        "\n",
        "    full_string+=unit_string\n",
        "# for loop ends  here\n",
        "\n",
        "full_string+=\"</units>\\n\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyVbka-A-hQM",
        "colab_type": "text"
      },
      "source": [
        "### 3.4.1 Wrinting to xml file\n",
        " String is created and than used to write in the xml file with its tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djGHt0wA-hQN",
        "colab_type": "code",
        "colab": {},
        "outputId": "87f9bf5d-1076-44da-fc8e-08268cd2647b"
      },
      "source": [
        "f = open(\"28905644.xml\", \"w+\")\n",
        "f.write(\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n\")\n",
        "f.write(full_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "706015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxtnDk4l-hQQ",
        "colab_type": "text"
      },
      "source": [
        "## 4) Conclusion\n",
        "The data for each of the 400 units have been obtained in json and xml by using python data types and regular expression and json library. The files **28905644.json** and **28905644.xml** are added to submission."
      ]
    }
  ]
}